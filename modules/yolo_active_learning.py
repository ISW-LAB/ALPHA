# modules/yolo_active_learning.py
"""
YOLO Active Learning í•µì‹¬ ëª¨ë“ˆ
YOLO íƒì§€ + Classification í•„í„°ë§ì„ ê²°í•©í•œ ë°˜ë³µì  í•™ìŠµ ì‹œìŠ¤í…œ
"""

import os
import cv2
import numpy as np
import torch
import yaml
import shutil
import time
import pandas as pd
from tqdm import tqdm
from pathlib import Path
from ultralytics import YOLO

# ë¡œì»¬ ëª¨ë“ˆ ì„í¬íŠ¸
from modules.object_classifier import ObjectClassifier

class YOLOActiveLearning:
    """
    YOLO ê¸°ë°˜ Active Learning ì‹œìŠ¤í…œ
    YOLO ê°ì²´ íƒì§€ì™€ Classification ëª¨ë¸ì„ ê²°í•©í•˜ì—¬ ë°˜ë³µì  í•™ìŠµì„ ìˆ˜í–‰
    """
    
    def __init__(self, model_path, classifier_path=None, image_dir=None, label_dir=None, output_dir=None, 
                 conf_threshold=0.25, iou_threshold=0.5, class_conf_threshold=0.5, max_cycles=5, gpu_num=0,
                 use_classifier=False):
        """
        YOLO Active Learning ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        
        Args:
            model_path (str): ì‚¬ì „ í•™ìŠµëœ YOLO ëª¨ë¸ ê²½ë¡œ
            classifier_path (str, optional): ì‚¬ì „ í•™ìŠµëœ ë¶„ë¥˜ ëª¨ë¸ ê²½ë¡œ
            image_dir (str): ì´ë¯¸ì§€ ë°ì´í„°ì…‹ ê²½ë¡œ
            label_dir (str): ì •ë‹µ ë¼ë²¨ ê²½ë¡œ
            output_dir (str): ê²°ê³¼ ì €ì¥ ê²½ë¡œ
            conf_threshold (float): ê°ì²´ ê²€ì¶œ ì‹ ë¢°ë„ ì„ê³„ê°’
            iou_threshold (float): IoU ì„ê³„ê°’
            class_conf_threshold (float): ë¶„ë¥˜ ëª¨ë¸ ì‹ ë¢°ë„ ì„ê³„ê°’
            max_cycles (int): ìµœëŒ€ í•™ìŠµ ë°˜ë³µ íšŸìˆ˜
            gpu_num (int): ì‚¬ìš©í•  GPU ë²ˆí˜¸
            use_classifier (bool): ë¶„ë¥˜ ëª¨ë¸ ì‚¬ìš© ì—¬ë¶€
        """
        # ê¸°ë³¸ ì„¤ì • ì €ì¥
        self.model_path = model_path
        self.classifier_path = classifier_path
        self.image_dir = image_dir
        self.label_dir = label_dir
        self.output_dir = output_dir
        self.conf_threshold = conf_threshold
        self.iou_threshold = iou_threshold
        self.class_conf_threshold = class_conf_threshold
        self.max_cycles = max_cycles
        self.gpu_num = gpu_num
        self.use_classifier = use_classifier
        
        # ëª¨ë¸ ì´ë¦„ ì¶”ì¶œ
        self.model_name = os.path.splitext(os.path.basename(model_path))[0]
        
        # GPU ì„¤ì •
        self.device = torch.device(f"cuda:{self.gpu_num}" if torch.cuda.is_available() else "cpu")
        
        print("ğŸ”§ YOLO Active Learning ì‹œìŠ¤í…œ ì„¤ì •:")
        print(f"  - YOLO ëª¨ë¸: {self.model_name}")
        print(f"  - ë¶„ë¥˜ ëª¨ë¸ ì‚¬ìš©: {self.use_classifier}")
        print(f"  - ìµœëŒ€ ì‚¬ì´í´: {self.max_cycles}")
        print(f"  - ì¥ì¹˜: {self.device}")
        print(f"  - ê²°ê³¼ ì €ì¥: {self.output_dir}")
        
        # ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„±
        self.create_directories()
        
        # YOLO ëª¨ë¸ ë¡œë“œ
        print("ğŸ“¥ YOLO ëª¨ë¸ ë¡œë”© ì¤‘...")
        self.model = YOLO(self.model_path)
        print("âœ… YOLO ëª¨ë¸ ë¡œë”© ì™„ë£Œ")
        
        # ë¶„ë¥˜ ëª¨ë¸ ë¡œë“œ (ì„ íƒì )
        self.classifier = None
        if self.use_classifier and self.classifier_path:
            print("ğŸ“¥ ë¶„ë¥˜ ëª¨ë¸ ë¡œë”© ì¤‘...")
            self.classifier = ObjectClassifier(
                self.classifier_path, 
                self.device, 
                self.class_conf_threshold, 
                self.gpu_num
            )
            print("âœ… ë¶„ë¥˜ ëª¨ë¸ ë¡œë”© ì™„ë£Œ")
        
        # ì„±ëŠ¥ ì§€í‘œ ì €ì¥ìš© ë°ì´í„°í”„ë ˆì„ ì´ˆê¸°í™”
        self.setup_metrics_tracking()
        
        # í†µê³„ ë³€ìˆ˜ ì´ˆê¸°í™”
        self.reset_statistics()
        
        print("âœ… YOLO Active Learning ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
        
    def create_directories(self):
        """í•„ìš”í•œ ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„±"""
        print("ğŸ“ ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„± ì¤‘...")
        
        # ê¸°ë³¸ ì¶œë ¥ ë””ë ‰í† ë¦¬
        os.makedirs(self.output_dir, exist_ok=True)
        
        # ê° í•™ìŠµ ì£¼ê¸°ë³„ ê²°ê³¼ ë””ë ‰í† ë¦¬
        for cycle in range(1, self.max_cycles + 1):
            cycle_dir = os.path.join(self.output_dir, f"cycle_{cycle}")
            
            # ê¸°ë³¸ ë””ë ‰í† ë¦¬ë“¤
            subdirs = ["detections", "labels", "training"]
            
            # ë¶„ë¥˜ ëª¨ë¸ ì‚¬ìš© ì‹œ ì¶”ê°€ ë””ë ‰í† ë¦¬
            if self.use_classifier:
                subdirs.extend(["filtered_detections", "filtered_labels"])
            
            for subdir in subdirs:
                os.makedirs(os.path.join(cycle_dir, subdir), exist_ok=True)
        
        # í›ˆë ¨ ë°ì´í„°ì…‹ ë””ë ‰í† ë¦¬
        self.dataset_dir = os.path.join(self.output_dir, "dataset")
        for split in ["train", "val"]:
            for data_type in ["images", "labels"]:
                os.makedirs(os.path.join(self.dataset_dir, data_type, split), exist_ok=True)
        
        print("âœ… ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„± ì™„ë£Œ")
    
    def setup_metrics_tracking(self):
        """ì„±ëŠ¥ ì§€í‘œ ì¶”ì  ì„¤ì •"""
        # ë©”íŠ¸ë¦­ ì»¬ëŸ¼ ì •ì˜
        columns = [
            'Cycle', 'Model', 'mAP50', 'Precision', 'Recall', 'F1-Score', 
            'Detected_Objects', 'Filtered_Objects'
        ]
        
        self.metrics_df = pd.DataFrame(columns=columns)
        self.metrics_file = os.path.join(self.output_dir, "performance_metrics.csv")
        
        # ê¸°ì¡´ ë©”íŠ¸ë¦­ íŒŒì¼ì´ ìˆìœ¼ë©´ ë¡œë“œ
        if os.path.exists(self.metrics_file):
            try:
                existing_metrics = pd.read_csv(self.metrics_file)
                self.metrics_df = existing_metrics
                print(f"ğŸ“Š ê¸°ì¡´ ë©”íŠ¸ë¦­ íŒŒì¼ ë¡œë“œ: {self.metrics_file}")
            except Exception as e:
                print(f"âš ï¸ ê¸°ì¡´ ë©”íŠ¸ë¦­ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
    
    def reset_statistics(self):
        """í†µê³„ ë³€ìˆ˜ ì´ˆê¸°í™”"""
        self.filtered_objects_count = 0
        self.detected_objects_count = 0
    
    def detect_and_classify_objects(self, image_path, cycle):
        """
        ì´ë¯¸ì§€ì—ì„œ ê°ì²´ë¥¼ íƒì§€í•˜ê³  ë¶„ë¥˜ ëª¨ë¸ë¡œ í•„í„°ë§
        
        Args:
            image_path (str): ì´ë¯¸ì§€ ê²½ë¡œ
            cycle (int): í˜„ì¬ í•™ìŠµ ì£¼ê¸°
            
        Returns:
            tuple: (íƒì§€ëœ ê°ì²´ ë¦¬ìŠ¤íŠ¸, í•„í„°ë§ëœ ê°ì²´ ë¦¬ìŠ¤íŠ¸, ì „ì²´ íƒì§€ ì´ë¯¸ì§€, í•„í„°ë§ëœ ì´ë¯¸ì§€)
        """
        # ì´ë¯¸ì§€ ë¡œë“œ
        img = cv2.imread(image_path)
        if img is None:
            print(f"âš ï¸ ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {image_path}")
            return [], [], None, None
        
        # YOLO ê°ì²´ íƒì§€ ìˆ˜í–‰
        try:
            results = self.model.predict(
                source=img, 
                conf=self.conf_threshold, 
                iou=self.iou_threshold,
                save=False,
                verbose=False
            )
        except Exception as e:
            print(f"âš ï¸ YOLO ì˜ˆì¸¡ ì‹¤íŒ¨: {str(e)}")
            return [], [], None, None
        
        # ê²°ê³¼ ì²˜ë¦¬
        result = results[0]
        detected_objects = []
        filtered_objects = []
        
        # ì‹œê°í™”ë¥¼ ìœ„í•œ ì´ë¯¸ì§€ ë³µì‚¬
        img_with_all_boxes = img.copy()
        img_with_filtered_boxes = img.copy() if self.use_classifier else None
        
        if len(result.boxes) > 0:
            # ê°ì²´ ì´ë¯¸ì§€ë“¤ì„ ë°°ì¹˜ë¡œ ì²˜ë¦¬í•˜ê¸° ìœ„í•œ ë¦¬ìŠ¤íŠ¸
            object_images = []
            object_infos = []
            
            for i, box in enumerate(result.boxes):
                x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                conf = box.conf[0].cpu().numpy()
                
                # ì¢Œí‘œ ì •ìˆ˜ ë³€í™˜ ë° ê²½ê³„ í™•ì¸
                x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)
                h, w = img.shape[:2]
                x1, y1 = max(0, x1), max(0, y1)
                x2, y2 = min(w, x2), min(h, y2)
                
                # ìœ íš¨í•œ ë°”ìš´ë”© ë°•ìŠ¤ì¸ì§€ í™•ì¸
                if x2 <= x1 or y2 <= y1:
                    continue
                
                # ê²€ì¶œëœ ê°ì²´ ì´ë¯¸ì§€ ì¶”ì¶œ
                obj_img = img[y1:y2, x1:x2]
                
                if obj_img.size == 0:
                    continue
                
                # YOLO í¬ë§·ìœ¼ë¡œ ì¢Œí‘œ ë³€í™˜ (ì •ê·œí™”ëœ ì¤‘ì‹¬ì , ë„ˆë¹„, ë†’ì´)
                center_x = ((x1 + x2) / 2) / w
                center_y = ((y1 + y2) / 2) / h
                width = (x2 - x1) / w
                height = (y2 - y1) / h
                
                # ê°ì²´ ì •ë³´ ì €ì¥
                obj_info = {
                    'cls_id': 0,  # ë‹¨ì¼ í´ë˜ìŠ¤
                    'center_x': center_x,
                    'center_y': center_y,
                    'width': width,
                    'height': height,
                    'confidence': conf,
                    'bbox': [x1, y1, x2, y2]
                }
                
                object_images.append(obj_img)
                object_infos.append(obj_info)
                
                # ëª¨ë“  íƒì§€ ê²°ê³¼ì— ë°•ìŠ¤ ê·¸ë¦¬ê¸°
                cv2.rectangle(img_with_all_boxes, (x1, y1), (x2, y2), (0, 255, 0), 2)
                cv2.putText(img_with_all_boxes, f"Obj {conf:.2f}", 
                           (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
            
            # ë¶„ë¥˜ ëª¨ë¸ ì‚¬ìš© ì‹œ ë°°ì¹˜ ë¶„ë¥˜ ìˆ˜í–‰
            if self.use_classifier and self.classifier and object_images:
                try:
                    # ë°°ì¹˜ ë¶„ë¥˜ ìˆ˜í–‰
                    classification_results = self.classifier.classify_batch(object_images)
                    
                    for obj_info, (pred_class, class_conf) in zip(object_infos, classification_results):
                        bbox = obj_info['bbox']
                        x1, y1, x2, y2 = bbox
                        
                        # ë¶„ë¥˜ ê²°ê³¼ì— ë”°ë¼ ê°ì²´ ë¶„ë¥˜
                        if pred_class == 0:  # Keep
                            detected_objects.append([
                                obj_info['cls_id'], obj_info['center_x'], obj_info['center_y'], 
                                obj_info['width'], obj_info['height']
                            ])
                            self.detected_objects_count += 1
                            
                            # ìœ ì§€í•  ê°ì²´ ì‹œê°í™” (ì´ˆë¡ìƒ‰)
                            cv2.rectangle(img_with_filtered_boxes, (x1, y1), (x2, y2), (0, 255, 0), 2)
                            cv2.putText(img_with_filtered_boxes, f"Keep {class_conf:.2f}", 
                                       (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
                        else:  # Filter
                            filtered_objects.append([
                                obj_info['cls_id'], obj_info['center_x'], obj_info['center_y'], 
                                obj_info['width'], obj_info['height']
                            ])
                            self.filtered_objects_count += 1
                            
                            # í•„í„°ë§ëœ ê°ì²´ ì‹œê°í™” (ë¹¨ê°„ìƒ‰)
                            cv2.rectangle(img_with_all_boxes, (x1, y1), (x2, y2), (0, 0, 255), 2)
                            cv2.putText(img_with_all_boxes, f"Filter {class_conf:.2f}", 
                                       (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)
                
                except Exception as e:
                    print(f"âš ï¸ ë¶„ë¥˜ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
                    # ë¶„ë¥˜ ì‹¤íŒ¨ ì‹œ ëª¨ë“  ê°ì²´ë¥¼ íƒì§€ëœ ê²ƒìœ¼ë¡œ ì²˜ë¦¬
                    for obj_info in object_infos:
                        detected_objects.append([
                            obj_info['cls_id'], obj_info['center_x'], obj_info['center_y'], 
                            obj_info['width'], obj_info['height']
                        ])
                        self.detected_objects_count += 1
            else:
                # ë¶„ë¥˜ ëª¨ë¸ ë¯¸ì‚¬ìš© ì‹œ ëª¨ë“  ê°ì²´ë¥¼ íƒì§€ëœ ê²ƒìœ¼ë¡œ ì²˜ë¦¬
                for obj_info in object_infos:
                    detected_objects.append([
                        obj_info['cls_id'], obj_info['center_x'], obj_info['center_y'], 
                        obj_info['width'], obj_info['height']
                    ])
                    self.detected_objects_count += 1
        
        return detected_objects, filtered_objects, img_with_all_boxes, img_with_filtered_boxes
    
    def save_label(self, objects, label_path):
        """
        íƒì§€ëœ ê°ì²´ë¥¼ YOLO í¬ë§· ë¼ë²¨ íŒŒì¼ë¡œ ì €ì¥
        
        Args:
            objects (list): ê°ì²´ ë¦¬ìŠ¤íŠ¸ [cls_id, center_x, center_y, width, height]
            label_path (str): ì €ì¥í•  ë¼ë²¨ íŒŒì¼ ê²½ë¡œ
        """
        try:
            os.makedirs(os.path.dirname(label_path), exist_ok=True)
            
            with open(label_path, 'w') as f:
                for obj in objects:
                    line = ' '.join([str(x) for x in obj])
                    f.write(line + '\n')
                    
        except Exception as e:
            print(f"âš ï¸ ë¼ë²¨ ì €ì¥ ì‹¤íŒ¨: {label_path} - {str(e)}")
    
    def prepare_dataset(self, cycle):
        """
        YOLO í•™ìŠµì„ ìœ„í•œ ë°ì´í„°ì…‹ ì¤€ë¹„
        
        Args:
            cycle (int): í˜„ì¬ í•™ìŠµ ì£¼ê¸°
        """
        print(f"ğŸ“¦ ì‚¬ì´í´ {cycle} ë°ì´í„°ì…‹ ì¤€ë¹„ ì¤‘...")
        
        # ì‚¬ìš©í•  ë¼ë²¨ ë””ë ‰í† ë¦¬ ê²°ì •
        if self.use_classifier:
            labels_source_dir = os.path.join(self.output_dir, f"cycle_{cycle}", "filtered_labels")
        else:
            labels_source_dir = os.path.join(self.output_dir, f"cycle_{cycle}", "labels")
        
        # ì´ë¯¸ì§€ íŒŒì¼ ëª©ë¡
        image_files = [f for f in os.listdir(self.image_dir) 
                      if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp'))]
        
        if not image_files:
            raise ValueError("ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        # ë°ì´í„°ì…‹ ë¶„í•  (ëŒ€ë¶€ë¶„ì„ í›ˆë ¨ìš©ìœ¼ë¡œ ì‚¬ìš©)
        total_images = len(image_files)
        if total_images > 10:
            val_count = max(5, min(20, int(total_images * 0.05)))  # 5% ë˜ëŠ” ìµœì†Œ 5ê°œ
        else:
            val_count = 1  # ìµœì†Œ 1ê°œëŠ” ê²€ì¦ìš©
        
        val_files = image_files[:val_count]
        train_files = image_files[val_count:]
        
        print(f"  - í›ˆë ¨: {len(train_files)}ê°œ")
        print(f"  - ê²€ì¦: {len(val_files)}ê°œ")
        
        # ê¸°ì¡´ ë°ì´í„°ì…‹ ë””ë ‰í† ë¦¬ ë¹„ìš°ê¸°
        for split in ["train", "val"]:
            for data_type in ["images", "labels"]:
                dir_path = os.path.join(self.dataset_dir, data_type, split)
                if os.path.exists(dir_path):
                    for file in os.listdir(dir_path):
                        file_path = os.path.join(dir_path, file)
                        if os.path.isfile(file_path):
                            os.remove(file_path)
        
        # ë°ì´í„° ë³µì‚¬ í•¨ìˆ˜
        def copy_files(file_list, split_name):
            copied_count = 0
            for img_file in file_list:
                # ì´ë¯¸ì§€ ë³µì‚¬
                src_img = os.path.join(self.image_dir, img_file)
                dst_img = os.path.join(self.dataset_dir, "images", split_name, img_file)
                
                if os.path.exists(src_img):
                    shutil.copy(src_img, dst_img)
                    
                    # ë¼ë²¨ ë³µì‚¬
                    label_file = os.path.splitext(img_file)[0] + '.txt'
                    src_label = os.path.join(labels_source_dir, label_file)
                    dst_label = os.path.join(self.dataset_dir, "labels", split_name, label_file)
                    
                    if os.path.exists(src_label):
                        shutil.copy(src_label, dst_label)
                        copied_count += 1
                    else:
                        # ë¼ë²¨ íŒŒì¼ì´ ì—†ëŠ” ê²½ìš° ë¹ˆ íŒŒì¼ ìƒì„±
                        with open(dst_label, 'w') as f:
                            pass
            
            return copied_count
        
        # íŒŒì¼ ë³µì‚¬ ì‹¤í–‰
        train_copied = copy_files(train_files, "train")
        val_copied = copy_files(val_files, "val")
        
        print(f"  âœ… ë°ì´í„°ì…‹ ì¤€ë¹„ ì™„ë£Œ: í›ˆë ¨ {train_copied}ê°œ, ê²€ì¦ {val_copied}ê°œ")
        
        # ë°ì´í„°ì…‹ YAML íŒŒì¼ ìƒì„±
        self.create_dataset_yaml()
    
    def create_dataset_yaml(self):
        """YOLO í•™ìŠµìš© ë°ì´í„°ì…‹ YAML íŒŒì¼ ìƒì„±"""
        dataset_yaml = {
            'path': os.path.abspath(self.dataset_dir),
            'train': 'images/train',
            'val': 'images/val', 
            'nc': 1,  # ë‹¨ì¼ í´ë˜ìŠ¤
            'names': ['object']
        }
        
        yaml_path = os.path.join(self.dataset_dir, 'dataset.yaml')
        try:
            with open(yaml_path, 'w') as f:
                yaml.dump(dataset_yaml, f, default_flow_style=False)
            
            print(f"ğŸ“„ ë°ì´í„°ì…‹ YAML ìƒì„±: {yaml_path}")
            return yaml_path
            
        except Exception as e:
            print(f"âš ï¸ YAML íŒŒì¼ ìƒì„± ì‹¤íŒ¨: {str(e)}")
            return None
    
    def train_model(self, cycle):
        """
        í˜„ì¬ ì£¼ê¸°ì˜ ë°ì´í„°ë¡œ YOLO ëª¨ë¸ í•™ìŠµ
        
        Args:
            cycle (int): í˜„ì¬ í•™ìŠµ ì£¼ê¸°
            
        Returns:
            str: í•™ìŠµëœ ëª¨ë¸ ê²½ë¡œ
        """
        print(f"ğŸ“ ì‚¬ì´í´ {cycle} YOLO ëª¨ë¸ í•™ìŠµ ì‹œì‘...")
        
        yaml_path = os.path.join(self.dataset_dir, 'dataset.yaml')
        if not os.path.exists(yaml_path):
            raise FileNotFoundError("ë°ì´í„°ì…‹ YAML íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤")
        
        # í•™ìŠµ ê²°ê³¼ ì €ì¥ ê²½ë¡œ
        training_dir = os.path.join(self.output_dir, f"cycle_{cycle}", "training")
        
        try:
            # ëª¨ë¸ í•™ìŠµ ì‹¤í–‰
            results = self.model.train(
                data=yaml_path,
                epochs=50,  # ì‚¬ì´í´ë‹¹ ì—í­ ìˆ˜
                imgsz=640,
                batch=16,
                patience=10,  # ì¡°ê¸° ì¢…ë£Œ
                project=training_dir,
                name="yolo_model",
                device=self.device,
                plots=True,  # í•™ìŠµ ê·¸ë˜í”„ ì €ì¥
                save_period=10  # 10 ì—í­ë§ˆë‹¤ ì €ì¥
            )
            
            # í•™ìŠµëœ ëª¨ë¸ ê²½ë¡œ
            trained_model_path = os.path.join(training_dir, "yolo_model", "weights", "best.pt")
            
            if os.path.exists(trained_model_path):
                # ëª¨ë¸ ì—…ë°ì´íŠ¸
                self.model = YOLO(trained_model_path)
                print(f"âœ… ëª¨ë¸ í•™ìŠµ ì™„ë£Œ: {trained_model_path}")
                return trained_model_path
            else:
                raise FileNotFoundError("í•™ìŠµëœ ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                
        except Exception as e:
            print(f"âŒ ëª¨ë¸ í•™ìŠµ ì‹¤íŒ¨: {str(e)}")
            raise
    
    def evaluate_performance(self, cycle):
        """
        ëª¨ë¸ ì„±ëŠ¥ í‰ê°€
        
        Args:
            cycle (int): í˜„ì¬ í•™ìŠµ ì£¼ê¸°
            
        Returns:
            dict: ì„±ëŠ¥ ì§€í‘œ ë”•ì…”ë„ˆë¦¬
        """
        print(f"ğŸ“Š ì‚¬ì´í´ {cycle} ì„±ëŠ¥ í‰ê°€ ì¤‘...")
        
        # ì´ë¯¸ì§€ íŒŒì¼ ëª©ë¡
        image_files = [f for f in os.listdir(self.image_dir) 
                      if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp'))]
        
        if not image_files:
            print("âš ï¸ í‰ê°€í•  ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤")
            return self._create_empty_metrics(cycle)
        
        # ì„±ëŠ¥ ì§€í‘œ ìˆ˜ì§‘
        all_precisions = []
        all_recalls = []
        all_f1_scores = []
        
        print(f"  ğŸ“¸ {len(image_files)}ê°œ ì´ë¯¸ì§€ í‰ê°€ ì¤‘...")
        
        for image_file in tqdm(image_files, desc="Evaluating"):
            image_path = os.path.join(self.image_dir, image_file)
            
            # í˜„ì¬ ëª¨ë¸ë¡œ ê°ì²´ íƒì§€
            detected_objects, _, _, _ = self.detect_and_classify_objects(image_path, cycle)
            
            # ì •ë‹µ ë¼ë²¨ ë¡œë“œ
            gt_label_path = os.path.join(self.label_dir, os.path.splitext(image_file)[0] + '.txt')
            gt_objects = self._load_ground_truth(gt_label_path)
            
            # ì„±ëŠ¥ ê³„ì‚° (ê°„ì†Œí™”ëœ ë°©ì‹)
            precision, recall, f1 = self._calculate_performance_metrics(detected_objects, gt_objects)
            
            all_precisions.append(precision)
            all_recalls.append(recall)
            all_f1_scores.append(f1)
        
        # í‰ê·  ì„±ëŠ¥ ê³„ì‚°
        avg_precision = np.mean(all_precisions)
        avg_recall = np.mean(all_recalls)
        avg_f1 = np.mean(all_f1_scores)
        
        # ë©”íŠ¸ë¦­ ë”•ì…”ë„ˆë¦¬ ìƒì„±
        metrics = {
            'Cycle': cycle,
            'Model': self.model_name,
            'mAP50': avg_precision,  # ê°„ì†Œí™”ëœ mAP
            'Precision': avg_precision,
            'Recall': avg_recall,
            'F1-Score': avg_f1,
            'Detected_Objects': self.detected_objects_count,
            'Filtered_Objects': self.filtered_objects_count if self.use_classifier else 0
        }
        
        # ë©”íŠ¸ë¦­ ì €ì¥
        self._save_metrics(metrics)
        
        print(f"  ğŸ“ˆ ì„±ëŠ¥ ê²°ê³¼:")
        print(f"    - mAP50: {avg_precision:.4f}")
        print(f"    - Precision: {avg_precision:.4f}")
        print(f"    - Recall: {avg_recall:.4f}")
        print(f"    - F1-Score: {avg_f1:.4f}")
        print(f"    - íƒì§€ ê°ì²´: {self.detected_objects_count}")
        if self.use_classifier:
            print(f"    - í•„í„°ë§ ê°ì²´: {self.filtered_objects_count}")
        
        return metrics
    
    def _load_ground_truth(self, gt_label_path):
        """ì •ë‹µ ë¼ë²¨ ë¡œë“œ"""
        gt_objects = []
        
        if os.path.exists(gt_label_path):
            try:
                with open(gt_label_path, 'r') as f:
                    for line in f:
                        values = line.strip().split()
                        if len(values) >= 5:
                            cls_id = 0  # ë‹¨ì¼ í´ë˜ìŠ¤ë¡œ ë³€í™˜
                            center_x = float(values[1])
                            center_y = float(values[2])
                            width = float(values[3])
                            height = float(values[4])
                            gt_objects.append([cls_id, center_x, center_y, width, height])
            except Exception as e:
                print(f"âš ï¸ ì •ë‹µ ë¼ë²¨ ë¡œë“œ ì‹¤íŒ¨: {gt_label_path} - {str(e)}")
        
        return gt_objects
    
    def _calculate_performance_metrics(self, detected_objects, gt_objects):
        """ì„±ëŠ¥ ì§€í‘œ ê³„ì‚° (ê°„ì†Œí™”ëœ ë°©ì‹)"""
        if len(gt_objects) == 0 and len(detected_objects) == 0:
            return 1.0, 1.0, 1.0
        elif len(gt_objects) == 0:
            return 0.0, 1.0, 0.0
        elif len(detected_objects) == 0:
            return 1.0, 0.0, 0.0
        else:
            # ê°„ì†Œí™”ëœ ë§¤ì¹­ ë°©ì‹ (ì‹¤ì œë¡œëŠ” IoU ê¸°ë°˜ ë§¤ì¹­ í•„ìš”)
            # ê°ì²´ ìˆ˜ ê¸°ë°˜ ê·¼ì‚¬ ê³„ì‚°
            precision = min(1.0, len(gt_objects) / len(detected_objects))
            recall = min(1.0, len(detected_objects) / len(gt_objects))
            
            if precision + recall > 0:
                f1 = 2 * precision * recall / (precision + recall)
            else:
                f1 = 0.0
            
            return precision, recall, f1
    
    def _create_empty_metrics(self, cycle):
        """ë¹ˆ ë©”íŠ¸ë¦­ ìƒì„±"""
        return {
            'Cycle': cycle,
            'Model': self.model_name,
            'mAP50': 0.0,
            'Precision': 0.0,
            'Recall': 0.0,
            'F1-Score': 0.0,
            'Detected_Objects': 0,
            'Filtered_Objects': 0
        }
    
    def _save_metrics(self, metrics):
        """ë©”íŠ¸ë¦­ì„ ë°ì´í„°í”„ë ˆì„ì— ì €ì¥"""
        # ê¸°ì¡´ ë©”íŠ¸ë¦­ì—ì„œ ë™ì¼í•œ Cycleê³¼ Model ì¡°í•© í™•ì¸
        mask = (self.metrics_df['Cycle'] == metrics['Cycle']) & \
               (self.metrics_df['Model'] == metrics['Model'])
        
        if any(mask):
            # ê¸°ì¡´ í•­ëª© ì—…ë°ì´íŠ¸
            for col, value in metrics.items():
                self.metrics_df.loc[mask, col] = value
        else:
            # ìƒˆ í•­ëª© ì¶”ê°€
            new_row = pd.DataFrame([metrics])
            self.metrics_df = pd.concat([self.metrics_df, new_row], ignore_index=True)
        
        # CSV íŒŒì¼ë¡œ ì €ì¥
        try:
            self.metrics_df.to_csv(self.metrics_file, index=False)
            print(f"  ğŸ’¾ ë©”íŠ¸ë¦­ ì €ì¥: {self.metrics_file}")
        except Exception as e:
            print(f"  âš ï¸ ë©”íŠ¸ë¦­ ì €ì¥ ì‹¤íŒ¨: {str(e)}")
    
    def run(self):
        """Active Learning í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰"""
        print("="*80)
        print(f"ğŸš€ YOLO Active Learning í”„ë¡œì„¸ìŠ¤ ì‹œì‘")
        print(f"   ëª¨ë¸: {self.model_name}")
        print(f"   ë¶„ë¥˜ ëª¨ë¸ ì‚¬ìš©: {self.use_classifier}")
        print(f"   ìµœëŒ€ ì‚¬ì´í´: {self.max_cycles}")
        print("="*80)
        
        total_start_time = time.time()
        
        # ê° í•™ìŠµ ì£¼ê¸° ì‹¤í–‰
        for cycle in range(1, self.max_cycles + 1):
            print(f"\nğŸ”„ í•™ìŠµ ì‚¬ì´í´ {cycle}/{self.max_cycles} ì‹œì‘")
            print("-" * 60)
            
            cycle_start_time = time.time()
            
            # í†µê³„ ì´ˆê¸°í™”
            self.reset_statistics()
            
            # 1. ê°ì²´ íƒì§€ ë° ë¶„ë¥˜
            self._process_images_for_cycle(cycle)
            
            # íƒì§€ëœ ê°ì²´ê°€ ì—†ìœ¼ë©´ ì¤‘ë‹¨
            if self.detected_objects_count == 0:
                print("âš ï¸ íƒì§€ëœ ê°ì²´ê°€ ì—†ìŠµë‹ˆë‹¤.")
                if cycle == 1:
                    raise Exception("ì²« ë²ˆì§¸ ì‚¬ì´í´ì—ì„œ íƒì§€ëœ ê°ì²´ê°€ ì—†ìŠµë‹ˆë‹¤.")
                
                # ë¹ˆ ë©”íŠ¸ë¦­ ì €ì¥ í›„ ë‹¤ìŒ ì‚¬ì´í´ë¡œ
                empty_metrics = self._create_empty_metrics(cycle)
                self._save_metrics(empty_metrics)
                continue
            
            # 2. ë°ì´í„°ì…‹ ì¤€ë¹„
            self.prepare_dataset(cycle)
            
            # 3. ëª¨ë¸ í•™ìŠµ
            try:
                trained_model_path = self.train_model(cycle)
            except Exception as e:
                print(f"âŒ ì‚¬ì´í´ {cycle} í•™ìŠµ ì‹¤íŒ¨: {str(e)}")
                empty_metrics = self._create_empty_metrics(cycle)
                self._save_metrics(empty_metrics)
                continue
            
            # 4. ì„±ëŠ¥ í‰ê°€
            metrics = self.evaluate_performance(cycle)
            
            # ì‚¬ì´í´ ì™„ë£Œ ì‹œê°„
            cycle_elapsed = time.time() - cycle_start_time
            print(f"âœ… ì‚¬ì´í´ {cycle} ì™„ë£Œ ({cycle_elapsed/60:.1f}ë¶„)")
        
        # ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì™„ë£Œ
        total_elapsed = time.time() - total_start_time
        
        print("\n" + "="*80)
        print("ğŸ‰ YOLO Active Learning í”„ë¡œì„¸ìŠ¤ ì™„ë£Œ!")
        print("="*80)
        print(f"ğŸ“Š ì‹¤í–‰ ì •ë³´:")
        print(f"   - ëª¨ë¸: {self.model_name}")
        print(f"   - ì™„ë£Œëœ ì‚¬ì´í´: {self.max_cycles}")
        print(f"   - ì´ ì‹¤í–‰ ì‹œê°„: {total_elapsed/60:.1f}ë¶„")
        print(f"   - ë¶„ë¥˜ ëª¨ë¸ ì‚¬ìš©: {self.use_classifier}")
        print(f"ğŸ“ ê²°ê³¼ ì €ì¥ ìœ„ì¹˜: {self.output_dir}")
        print(f"ğŸ“ˆ ì„±ëŠ¥ ë©”íŠ¸ë¦­: {self.metrics_file}")
        
        # ìµœì¢… ì„±ëŠ¥ ìš”ì•½
        if not self.metrics_df.empty:
            final_metrics = self.metrics_df.iloc[-1]
            print(f"\nğŸ† ìµœì¢… ì„±ëŠ¥:")
            print(f"   - F1-Score: {final_metrics['F1-Score']:.4f}")
            print(f"   - Precision: {final_metrics['Precision']:.4f}")
            print(f"   - Recall: {final_metrics['Recall']:.4f}")
    
    def _process_images_for_cycle(self, cycle):
        """ì‚¬ì´í´ë³„ ì´ë¯¸ì§€ ì²˜ë¦¬"""
        print("1ï¸âƒ£ ê°ì²´ íƒì§€ ë° ë¶„ë¥˜ ìˆ˜í–‰ ì¤‘...")
        
        # ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬
        cycle_dir = os.path.join(self.output_dir, f"cycle_{cycle}")
        detections_dir = os.path.join(cycle_dir, "detections")
        labels_dir = os.path.join(cycle_dir, "labels")
        
        if self.use_classifier:
            filtered_detections_dir = os.path.join(cycle_dir, "filtered_detections")
            filtered_labels_dir = os.path.join(cycle_dir, "filtered_labels")
        
        # ì´ë¯¸ì§€ íŒŒì¼ ëª©ë¡
        image_files = [f for f in os.listdir(self.image_dir) 
                      if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp'))]
        
        if not image_files:
            raise ValueError("ì²˜ë¦¬í•  ì´ë¯¸ì§€ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤")
        
        print(f"   ğŸ“¸ ì²˜ë¦¬í•  ì´ë¯¸ì§€: {len(image_files)}ê°œ")
        
        # ê° ì´ë¯¸ì§€ ì²˜ë¦¬
        for image_file in tqdm(image_files, desc="Processing Images"):
            image_path = os.path.join(self.image_dir, image_file)
            
            # ê°ì²´ íƒì§€ ë° ë¶„ë¥˜
            detected_objects, filtered_objects, img_all, img_filtered = \
                self.detect_and_classify_objects(image_path, cycle)
            
            # íƒì§€ ê²°ê³¼ ì´ë¯¸ì§€ ì €ì¥
            if img_all is not None:
                cv2.imwrite(os.path.join(detections_dir, image_file), img_all)
            
            if self.use_classifier and img_filtered is not None:
                cv2.imwrite(os.path.join(filtered_detections_dir, image_file), img_filtered)
            
            # ë¼ë²¨ íŒŒì¼ ì €ì¥
            label_name = os.path.splitext(image_file)[0] + '.txt'
            
            if self.use_classifier:
                # ëª¨ë“  íƒì§€ ê²°ê³¼ì™€ í•„í„°ë§ëœ ê²°ê³¼ ëª¨ë‘ ì €ì¥
                all_objects = detected_objects + filtered_objects
                self.save_label(all_objects, os.path.join(labels_dir, label_name))
                self.save_label(detected_objects, os.path.join(filtered_labels_dir, label_name))
            else:
                # ë¶„ë¥˜ ëª¨ë¸ ë¯¸ì‚¬ìš© ì‹œ ëª¨ë“  íƒì§€ ê²°ê³¼ ì €ì¥
                self.save_label(detected_objects, os.path.join(labels_dir, label_name))
        
        # ì²˜ë¦¬ ê²°ê³¼ ì¶œë ¥
        print(f"   âœ… íƒì§€ëœ ê°ì²´: {self.detected_objects_count}ê°œ")
        if self.use_classifier:
            print(f"   ğŸ” í•„í„°ë§ëœ ê°ì²´: {self.filtered_objects_count}ê°œ")
            if self.detected_objects_count + self.filtered_objects_count > 0:
                keep_rate = self.detected_objects_count / (self.detected_objects_count + self.filtered_objects_count) * 100
                print(f"   ğŸ“Š ìœ ì§€ ë¹„ìœ¨: {keep_rate:.1f}%")

if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    print("ğŸ§ª YOLO Active Learning ëª¨ë“ˆ í…ŒìŠ¤íŠ¸")
    
    # í…ŒìŠ¤íŠ¸ ì„¤ì •
    active_learning = YOLOActiveLearning(
        model_path="./models/initial_yolo/yolov8_100pct.pt",
        classifier_path="./models/classification/densenet121_100.pth",
        image_dir="./dataset/images",
        label_dir="./dataset/labels",
        output_dir="./results/test_active_learning",
        conf_threshold=0.25,
        iou_threshold=0.5,
        class_conf_threshold=0.5,
        max_cycles=3,  # í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ ì¤„ì„
        gpu_num=0,
        use_classifier=True
    )
    
    # Active Learning ì‹¤í–‰
    try:
        active_learning.run()
        print("âœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}")
        import traceback
        traceback.print_exc()