# modules/object_classifier.py
"""
ê°ì²´ ë¶„ë¥˜ ëª¨ë¸ ëª¨ë“ˆ
í•™ìŠµëœ DenseNet ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ íƒì§€ëœ ê°ì²´ë¥¼ ë¶„ë¥˜í•˜ëŠ” ëª¨ë“ˆ
"""

import os
import cv2
import torch
import torch.nn as nn
from torchvision import models, transforms
from PIL import Image
import numpy as np

class ObjectClassifier:
    """
    ê°ì²´ ë¶„ë¥˜ê¸° í´ë˜ìŠ¤
    YOLOë¡œ íƒì§€ëœ ê°ì²´ë¥¼ Class 0 (Keep) ë˜ëŠ” Class 1 (Filter)ë¡œ ë¶„ë¥˜
    """
    
    def __init__(self, model_path, device=None, conf_threshold=0.5, gpu_num=0):
        """
        ê°ì²´ ë¶„ë¥˜ ëª¨ë¸ ì´ˆê¸°í™”
        
        Args:
            model_path (str): ì‚¬ì „ í•™ìŠµëœ ë¶„ë¥˜ ëª¨ë¸ ê²½ë¡œ (.pth íŒŒì¼)
            device (torch.device): ì—°ì‚° ì¥ì¹˜ (Noneì´ë©´ ìë™ ì„ íƒ)
            conf_threshold (float): ë¶„ë¥˜ ì‹ ë¢°ë„ ì„ê³„ê°’
            gpu_num (int): ì‚¬ìš©í•  GPU ë²ˆí˜¸
        """
        # ì¥ì¹˜ ì„¤ì •
        if device is None:
            self.device = torch.device(f"cuda:{gpu_num}" if torch.cuda.is_available() else "cpu")
        else:
            self.device = device
            
        self.conf_threshold = conf_threshold
        self.model_path = model_path
        
        print(f"ğŸ”§ ë¶„ë¥˜ ëª¨ë¸ ì¥ì¹˜: {self.device}")
        print(f"ğŸ“ ëª¨ë¸ ê²½ë¡œ: {model_path}")
        print(f"ğŸ¯ ì‹ ë¢°ë„ ì„ê³„ê°’: {conf_threshold}")
        
        # ëª¨ë¸ êµ¬ì¡° ìƒì„±
        self.model = self._create_model()
        
        # ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¡œë“œ
        self._load_model_weights()
        
        # ëª¨ë¸ì„ í‰ê°€ ëª¨ë“œë¡œ ì„¤ì •
        self.model.eval()
        
        # ì´ë¯¸ì§€ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì„¤ì •
        self.transform = transforms.Compose([
            transforms.Resize((224, 224)),  # DenseNet ì…ë ¥ í¬ê¸°
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # ImageNet ì •ê·œí™”
        ])
        
        print("âœ… ê°ì²´ ë¶„ë¥˜ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
        
    def _create_model(self):
        """DenseNet121 ëª¨ë¸ êµ¬ì¡° ìƒì„±"""
        print("ğŸ—ï¸ DenseNet121 ëª¨ë¸ êµ¬ì¡° ìƒì„± ì¤‘...")
        
        # DenseNet121 ëª¨ë¸ ì´ˆê¸°í™” (ì‚¬ì „ í›ˆë ¨ ê°€ì¤‘ì¹˜ ì—†ì´)
        model = models.densenet121(pretrained=False)
        
        # ì´ì§„ ë¶„ë¥˜ë¥¼ ìœ„í•´ ë§ˆì§€ë§‰ ë ˆì´ì–´ ìˆ˜ì •
        num_features = model.classifier.in_features
        model.classifier = nn.Sequential(
            nn.Dropout(0.3),  # ë“œë¡­ì•„ì›ƒ ë ˆì´ì–´
            nn.Linear(num_features, 2)  # 2 í´ë˜ìŠ¤ ì¶œë ¥ (0: Keep, 1: Filter)
        )
        
        model = model.to(self.device)
        print("âœ… ëª¨ë¸ êµ¬ì¡° ìƒì„± ì™„ë£Œ")
        
        return model
        
    def _load_model_weights(self):
        """ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¡œë“œ"""
        if not os.path.exists(self.model_path):
            raise FileNotFoundError(f"ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.model_path}")
        
        try:
            print("ğŸ“¥ ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¡œë”© ì¤‘...")
            
            # ê°€ì¤‘ì¹˜ ë¡œë“œ
            state_dict = torch.load(self.model_path, map_location=self.device)
            self.model.load_state_dict(state_dict)
            
            print("âœ… ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¡œë”© ì„±ê³µ")
            
        except RuntimeError as e:
            print(f"âš ï¸ ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¡œë”© ì‹¤íŒ¨: {e}")
            print("ğŸ”„ í‚¤ ë§¤í•‘ì„ ì‹œë„í•©ë‹ˆë‹¤...")
            
            try:
                # DataParallelë¡œ ì €ì¥ëœ ê²½ìš° 'module.' ì ‘ë‘ì‚¬ ì œê±°
                new_state_dict = {}
                for key, value in state_dict.items():
                    if 'module.' in key:
                        key = key.replace('module.', '')
                    new_state_dict[key] = value
                
                self.model.load_state_dict(new_state_dict)
                print("âœ… í‚¤ ë§¤í•‘ í›„ ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¡œë”© ì„±ê³µ")
                
            except Exception as e2:
                print(f"âŒ ëª¨ë¸ ë¡œë”© ìµœì¢… ì‹¤íŒ¨: {e2}")
                raise Exception(f"ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e2}")
    
    def preprocess_image(self, image):
        """
        ì´ë¯¸ì§€ ì „ì²˜ë¦¬
        
        Args:
            image (numpy.ndarray): OpenCV í˜•ì‹ì˜ ì´ë¯¸ì§€ (BGR)
            
        Returns:
            torch.Tensor: ì „ì²˜ë¦¬ëœ ì´ë¯¸ì§€ í…ì„œ
        """
        # ì´ë¯¸ì§€ í¬ê¸° ê²€ì‚¬
        if image.shape[0] < 10 or image.shape[1] < 10:
            print("âš ï¸ ì´ë¯¸ì§€ê°€ ë„ˆë¬´ ì‘ìŠµë‹ˆë‹¤ (10x10 ë¯¸ë§Œ)")
            return None
        
        # ì´ë¯¸ì§€ê°€ ë¹„ì–´ìˆëŠ”ì§€ í™•ì¸
        if image.size == 0:
            print("âš ï¸ ë¹ˆ ì´ë¯¸ì§€ì…ë‹ˆë‹¤")
            return None
        
        try:
            # OpenCV ì´ë¯¸ì§€ (BGR)ë¥¼ PIL ì´ë¯¸ì§€ (RGB)ë¡œ ë³€í™˜
            if len(image.shape) == 3:
                # ì»¬ëŸ¬ ì´ë¯¸ì§€
                pil_image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
            else:
                # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ì´ë¯¸ì§€
                pil_image = Image.fromarray(image).convert('RGB')
            
            # ì „ì²˜ë¦¬ ì ìš©
            input_tensor = self.transform(pil_image)
            
            # ë°°ì¹˜ ì°¨ì› ì¶”ê°€ [C, H, W] -> [1, C, H, W]
            input_tensor = input_tensor.unsqueeze(0)
            
            return input_tensor.to(self.device)
            
        except Exception as e:
            print(f"âš ï¸ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
            return None
    
    def classify(self, image):
        """
        ê°ì²´ ì´ë¯¸ì§€ ë¶„ë¥˜ ìˆ˜í–‰
        
        Args:
            image (numpy.ndarray): ë¶„ë¥˜í•  ê°ì²´ ì´ë¯¸ì§€ (OpenCV í˜•ì‹, BGR)
            
        Returns:
            tuple: (ì˜ˆì¸¡ í´ë˜ìŠ¤, ì‹ ë¢°ë„)
                - ì˜ˆì¸¡ í´ë˜ìŠ¤: 0 (Keep) ë˜ëŠ” 1 (Filter)
                - ì‹ ë¢°ë„: 0.0 ~ 1.0 ì‚¬ì´ì˜ í™•ë¥ ê°’
        """
        # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
        input_tensor = self.preprocess_image(image)
        
        if input_tensor is None:
            # ì „ì²˜ë¦¬ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’ ë°˜í™˜ (í•„í„°ë§)
            return 1, 0.0
        
        try:
            # ì˜ˆì¸¡ ìˆ˜í–‰ (ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚° ë¹„í™œì„±í™”)
            with torch.no_grad():
                # ëª¨ë¸ forward pass
                outputs = self.model(input_tensor)
                
                # Softmaxë¥¼ ì ìš©í•˜ì—¬ í™•ë¥  ê³„ì‚°
                probabilities = torch.nn.functional.softmax(outputs, dim=1)
                
                # ìµœëŒ€ í™•ë¥ ê³¼ í•´ë‹¹ í´ë˜ìŠ¤ ì„ íƒ
                confidence, predicted_class = torch.max(probabilities, 1)
                
                # CPUë¡œ ì´ë™í•˜ê³  numpy ê°’ìœ¼ë¡œ ë³€í™˜
                predicted_class = predicted_class.item()
                confidence = confidence.item()
                
                return predicted_class, confidence
                
        except Exception as e:
            print(f"âš ï¸ ë¶„ë¥˜ ì˜ˆì¸¡ ì‹¤íŒ¨: {str(e)}")
            # ì˜¤ë¥˜ ì‹œ ê¸°ë³¸ê°’ ë°˜í™˜ (í•„í„°ë§)
            return 1, 0.0
    
    def classify_batch(self, images):
        """
        ì—¬ëŸ¬ ì´ë¯¸ì§€ë¥¼ ë°°ì¹˜ë¡œ ë¶„ë¥˜
        
        Args:
            images (list): OpenCV ì´ë¯¸ì§€ë“¤ì˜ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            list: [(ì˜ˆì¸¡ í´ë˜ìŠ¤, ì‹ ë¢°ë„), ...] í˜•íƒœì˜ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        if not images:
            return []
        
        print(f"ğŸ” ë°°ì¹˜ ë¶„ë¥˜ ì‹œì‘: {len(images)}ê°œ ì´ë¯¸ì§€")
        
        # ë°°ì¹˜ í…ì„œ ì¤€ë¹„
        batch_tensors = []
        valid_indices = []
        
        for i, image in enumerate(images):
            tensor = self.preprocess_image(image)
            if tensor is not None:
                batch_tensors.append(tensor.squeeze(0))  # ë°°ì¹˜ ì°¨ì› ì œê±°
                valid_indices.append(i)
        
        if not batch_tensors:
            print("âš ï¸ ìœ íš¨í•œ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤")
            return [(1, 0.0)] * len(images)
        
        try:
            # ë°°ì¹˜ í…ì„œ ìƒì„±
            batch_tensor = torch.stack(batch_tensors).to(self.device)
            
            # ë°°ì¹˜ ì˜ˆì¸¡
            with torch.no_grad():
                outputs = self.model(batch_tensor)
                probabilities = torch.nn.functional.softmax(outputs, dim=1)
                confidences, predicted_classes = torch.max(probabilities, 1)
                
                # CPUë¡œ ì´ë™
                predicted_classes = predicted_classes.cpu().numpy()
                confidences = confidences.cpu().numpy()
            
            # ê²°ê³¼ ë§¤í•‘
            results = [(1, 0.0)] * len(images)  # ê¸°ë³¸ê°’ìœ¼ë¡œ ì´ˆê¸°í™”
            
            for i, valid_idx in enumerate(valid_indices):
                results[valid_idx] = (int(predicted_classes[i]), float(confidences[i]))
            
            print(f"âœ… ë°°ì¹˜ ë¶„ë¥˜ ì™„ë£Œ")
            return results
            
        except Exception as e:
            print(f"âš ï¸ ë°°ì¹˜ ë¶„ë¥˜ ì‹¤íŒ¨: {str(e)}")
            return [(1, 0.0)] * len(images)
    
    def get_class_name(self, class_id):
        """
        í´ë˜ìŠ¤ IDë¥¼ ì´ë¦„ìœ¼ë¡œ ë³€í™˜
        
        Args:
            class_id (int): í´ë˜ìŠ¤ ID (0 ë˜ëŠ” 1)
            
        Returns:
            str: í´ë˜ìŠ¤ ì´ë¦„
        """
        class_names = {0: "Keep", 1: "Filter"}
        return class_names.get(class_id, "Unknown")
    
    def evaluate_confidence(self, confidence):
        """
        ì‹ ë¢°ë„ ìˆ˜ì¤€ í‰ê°€
        
        Args:
            confidence (float): ì‹ ë¢°ë„ ê°’
            
        Returns:
            str: ì‹ ë¢°ë„ ìˆ˜ì¤€ ("High", "Medium", "Low")
        """
        if confidence >= 0.8:
            return "High"
        elif confidence >= 0.6:
            return "Medium"
        else:
            return "Low"
    
    def classify_with_details(self, image):
        """
        ìƒì„¸ ì •ë³´ì™€ í•¨ê»˜ ë¶„ë¥˜ ìˆ˜í–‰
        
        Args:
            image (numpy.ndarray): ë¶„ë¥˜í•  ê°ì²´ ì´ë¯¸ì§€
            
        Returns:
            dict: ìƒì„¸ ë¶„ë¥˜ ê²°ê³¼
        """
        predicted_class, confidence = self.classify(image)
        
        result = {
            'predicted_class': predicted_class,
            'class_name': self.get_class_name(predicted_class),
            'confidence': confidence,
            'confidence_level': self.evaluate_confidence(confidence),
            'should_keep': predicted_class == 0,
            'above_threshold': confidence >= self.conf_threshold
        }
        
        return result
    
    def filter_objects(self, detected_objects, images):
        """
        íƒì§€ëœ ê°ì²´ë“¤ì„ ë¶„ë¥˜í•˜ì—¬ í•„í„°ë§
        
        Args:
            detected_objects (list): íƒì§€ëœ ê°ì²´ ì •ë³´ ë¦¬ìŠ¤íŠ¸
            images (list): ê°ì²´ ì´ë¯¸ì§€ë“¤ì˜ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            tuple: (ìœ ì§€í•  ê°ì²´ë“¤, í•„í„°ë§ëœ ê°ì²´ë“¤)
        """
        keep_objects = []
        filter_objects = []
        
        print(f"ğŸ” ê°ì²´ í•„í„°ë§ ì‹œì‘: {len(detected_objects)}ê°œ ê°ì²´")
        
        # ë°°ì¹˜ ë¶„ë¥˜ ìˆ˜í–‰
        classification_results = self.classify_batch(images)
        
        for i, (obj_info, (pred_class, confidence)) in enumerate(zip(detected_objects, classification_results)):
            classification_detail = {
                'index': i,
                'predicted_class': pred_class,
                'class_name': self.get_class_name(pred_class),
                'confidence': confidence,
                'above_threshold': confidence >= self.conf_threshold,
                'object_info': obj_info
            }
            
            if pred_class == 0:  # Keep
                keep_objects.append(classification_detail)
            else:  # Filter
                filter_objects.append(classification_detail)
        
        print(f"ğŸ“Š í•„í„°ë§ ê²°ê³¼:")
        print(f"  - ìœ ì§€: {len(keep_objects)}ê°œ")
        print(f"  - í•„í„°ë§: {len(filter_objects)}ê°œ")
        
        return keep_objects, filter_objects
    
    def save_classification_results(self, results, save_path):
        """
        ë¶„ë¥˜ ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥
        
        Args:
            results (list): ë¶„ë¥˜ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
            save_path (str): ì €ì¥ ê²½ë¡œ
        """
        try:
            import json
            
            # ê²°ê³¼ë¥¼ JSON ì§ë ¬í™” ê°€ëŠ¥í•œ í˜•íƒœë¡œ ë³€í™˜
            serializable_results = []
            for result in results:
                if isinstance(result, dict):
                    serializable_results.append(result)
                else:
                    # tupleì¸ ê²½ìš° dictë¡œ ë³€í™˜
                    serializable_results.append({
                        'predicted_class': result[0],
                        'confidence': result[1],
                        'class_name': self.get_class_name(result[0])
                    })
            
            with open(save_path, 'w') as f:
                json.dump(serializable_results, f, indent=2)
            
            print(f"ğŸ’¾ ë¶„ë¥˜ ê²°ê³¼ ì €ì¥: {save_path}")
            
        except Exception as e:
            print(f"âš ï¸ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {str(e)}")
    
    def get_model_info(self):
        """
        ëª¨ë¸ ì •ë³´ ë°˜í™˜
        
        Returns:
            dict: ëª¨ë¸ ì •ë³´
        """
        # ëª¨ë¸ íŒŒë¼ë¯¸í„° ìˆ˜ ê³„ì‚°
        total_params = sum(p.numel() for p in self.model.parameters())
        trainable_params = sum(p.numel() for p in self.model.parameters() if p.requires_grad)
        
        return {
            'model_path': self.model_path,
            'device': str(self.device),
            'confidence_threshold': self.conf_threshold,
            'total_parameters': total_params,
            'trainable_parameters': trainable_params,
            'model_architecture': 'DenseNet121',
            'num_classes': 2,
            'class_names': ['Keep', 'Filter']
        }
    
    def __str__(self):
        """ë¬¸ìì—´ í‘œí˜„"""
        info = self.get_model_info()
        return f"""ObjectClassifier(
    Model: {info['model_architecture']}
    Device: {info['device']}
    Classes: {info['num_classes']} ({', '.join(info['class_names'])})
    Confidence Threshold: {info['confidence_threshold']}
    Parameters: {info['total_parameters']:,}
    Model Path: {info['model_path']}
)"""

# í…ŒìŠ¤íŠ¸ ë° ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
def test_classifier(model_path, test_images_dir, output_dir=None):
    """
    ë¶„ë¥˜ê¸° í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
    
    Args:
        model_path (str): ë¶„ë¥˜ ëª¨ë¸ ê²½ë¡œ
        test_images_dir (str): í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬
        output_dir (str): ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬
    """
    print("ğŸ§ª ë¶„ë¥˜ê¸° í…ŒìŠ¤íŠ¸ ì‹œì‘")
    
    # ë¶„ë¥˜ê¸° ì´ˆê¸°í™”
    classifier = ObjectClassifier(model_path)
    print(classifier)
    
    # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ë¡œë“œ
    test_images = []
    image_paths = []
    
    for filename in os.listdir(test_images_dir):
        if filename.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp')):
            img_path = os.path.join(test_images_dir, filename)
            img = cv2.imread(img_path)
            if img is not None:
                test_images.append(img)
                image_paths.append(img_path)
    
    if not test_images:
        print("âŒ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        return
    
    print(f"ğŸ“¸ {len(test_images)}ê°œ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ë¡œë“œë¨")
    
    # ë¶„ë¥˜ ìˆ˜í–‰
    results = []
    for i, (img, img_path) in enumerate(zip(test_images, image_paths)):
        result = classifier.classify_with_details(img)
        result['image_path'] = img_path
        result['filename'] = os.path.basename(img_path)
        results.append(result)
        
        print(f"ğŸ“Š {i+1:3d}. {result['filename']:20s} -> "
              f"{result['class_name']:6s} ({result['confidence']:.3f}, {result['confidence_level']})")
    
    # í†µê³„ ì¶œë ¥
    keep_count = sum(1 for r in results if r['predicted_class'] == 0)
    filter_count = len(results) - keep_count
    avg_confidence = np.mean([r['confidence'] for r in results])
    
    print(f"\nğŸ“ˆ í…ŒìŠ¤íŠ¸ ê²°ê³¼ í†µê³„:")
    print(f"  - Keep: {keep_count}ê°œ ({keep_count/len(results)*100:.1f}%)")
    print(f"  - Filter: {filter_count}ê°œ ({filter_count/len(results)*100:.1f}%)")
    print(f"  - í‰ê·  ì‹ ë¢°ë„: {avg_confidence:.3f}")
    
    # ê²°ê³¼ ì €ì¥
    if output_dir:
        os.makedirs(output_dir, exist_ok=True)
        classifier.save_classification_results(results, 
                                             os.path.join(output_dir, 'test_results.json'))

if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì˜ˆì‹œ
    print("ğŸ” ObjectClassifier ëª¨ë“ˆ í…ŒìŠ¤íŠ¸")
    
    # ëª¨ë¸ ê²½ë¡œ ì„¤ì • (ì‹¤ì œ ê²½ë¡œë¡œ ë³€ê²½ í•„ìš”)
    model_path = "./models/classification/densenet121_100.pth"
    test_images_dir = "./test_images"
    output_dir = "./test_results"
    
    if os.path.exists(model_path):
        test_classifier(model_path, test_images_dir, output_dir)
    else:
        print(f"âŒ ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_path}")
        print("ë¶„ë¥˜ ëª¨ë¸ì„ ë¨¼ì € í•™ìŠµì‹œì¼œì£¼ì„¸ìš”.")